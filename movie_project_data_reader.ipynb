{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\AliPe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import packages here\n",
    "import pandas as pd\n",
    "import os\n",
    "import opendatasets as od\n",
    "from datetime import datetime\n",
    "\n",
    "# Download NLTK tokenizer data (if not already downloaded)\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies\n",
      "Downloading tmdb-movies-dataset-2023-930k-movies.zip to .\\tmdb-movies-dataset-2023-930k-movies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189M/189M [00:13<00:00, 15.0MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign the Kaggle data set URL into variable\n",
    "dataset = 'https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies/data'\n",
    "od.download(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign data types to DataFrame columns\n",
    "def assign_data_types(df):\n",
    "    '''\n",
    "    Assign specified data types to DataFrame columns.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): Input DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame with assigned data types.\n",
    "    '''\n",
    "    # Define mapping of column names to desired data types\n",
    "    column_types = {\n",
    "        'id': int,\n",
    "        'title': str,\n",
    "        'vote_average': float,\n",
    "        'vote_count': int,\n",
    "        'status': str,\n",
    "        'revenue': float,\n",
    "        'runtime': int,\n",
    "        'adult': bool,\n",
    "        'backdrop_path': str,\n",
    "        'budget': float,\n",
    "        'homepage': str,\n",
    "        'imdb_id': str,\n",
    "        'original_language': str,\n",
    "        'original_title': str,\n",
    "        'overview': str,\n",
    "        'popularity': float,\n",
    "        'poster_path': str,\n",
    "        'tagline': str,\n",
    "        'genres': str,\n",
    "        'production_companies': str,\n",
    "        'production_countries': str,\n",
    "        'spoken_languages': str,\n",
    "        'release_year': int\n",
    "    }\n",
    "    \n",
    "    # Apply specified data types to DataFrame columns\n",
    "    for column, data_type in column_types.items():\n",
    "        if column in df.columns:\n",
    "            df[column] = df[column].astype(data_type)\n",
    "    \n",
    "    # Change the release_date manually as we cannot do it in the loop (apparently)\n",
    "    df['release_date'] = pd.to_datetime(df['release_date'], format='%Y-%m-%d')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to tokenize overview into sentences\n",
    "def tokenize_into_sentences(overview):\n",
    "    '''\n",
    "    Tokenize overview into sentences using NLTK sent_tokenize.\n",
    "    \n",
    "    Parameters:\n",
    "        overview (str): Input overview text.\n",
    "        \n",
    "    Returns:\n",
    "        list: List of sentences extracted from the overview.\n",
    "    '''\n",
    "    if isinstance(overview, str):\n",
    "        return sent_tokenize(overview)\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Define the main processing pipeline function\n",
    "def process_movie_data(df, drop_na=False):\n",
    "    '''\n",
    "    Process movie data by applying data type assignment, filtering, tokenization, and date filtering.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): Input DataFrame containing movie data.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Processed DataFrame with cleaned and filtered movie data.\n",
    "    '''\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Apply data type assignment to the DataFrame\n",
    "    assign_data_types(df_copy)\n",
    "\n",
    "    # Filter for movies with 'status' == 'Released' \n",
    "    released_movies_df = df_copy[df_copy['status'] == 'Released']\n",
    "\n",
    "    # Filter for NA values\n",
    "    if drop_na:\n",
    "        released_movies_df = released_movies_df.dropna()\n",
    "\n",
    "    # Drop specified columns\n",
    "    released_movies_df = released_movies_df.drop(columns=['backdrop_path', 'homepage', 'poster_path'])\n",
    "\n",
    "    # Apply sentence tokenization to 'overview' column\n",
    "    released_movies_df['overview'] = released_movies_df['overview'].apply(tokenize_into_sentences)\n",
    "\n",
    "    # Process 'tagline', 'genres', 'production_companies', 'production_countries', 'spoken_languages' columns\n",
    "    columns_to_split = ['tagline', 'genres', 'production_companies', 'production_countries', 'spoken_languages']\n",
    "    for col in columns_to_split:\n",
    "        released_movies_df[col] = released_movies_df[col].apply(lambda x: x.split(', ') if isinstance(x, str) else [])\n",
    "\n",
    "    # Define start and end dates for filtering\n",
    "    start_date = '1900-01-01'\n",
    "    end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Filter DataFrame between start_date and end_date\n",
    "    date_filtered_released_df = released_movies_df[(released_movies_df['release_date'] >= start_date) & (released_movies_df['release_date'] <= end_date)]\n",
    "\n",
    "    # Return data sorted by release date in ascending order\n",
    "    return date_filtered_released_df.sort_values(by=['release_date'], ascending=[True])\n",
    "\n",
    "# Function to write the processed DataFrame to CSV\n",
    "def write_processed_movie_data(df, processed_csv_path):\n",
    "    '''\n",
    "    Write processed DataFrame to CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): Processed DataFrame.\n",
    "        processed_csv_path (str): Path to save the processed CSV file.\n",
    "    '''\n",
    "    # Write the processed DataFrame to CSV while preserving data types\n",
    "    df.to_csv(processed_csv_path, index=False, encoding='utf-8')\n",
    "\n",
    "# Function to read the processed DataFrame from CSV\n",
    "def read_clean_movie_data(processed_csv_path):\n",
    "    '''\n",
    "    Read processed DataFrame from CSV file with specified data types.\n",
    "    \n",
    "    Parameters:\n",
    "        processed_csv_path (str): Path to the processed CSV file.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Processed DataFrame read from CSV with assigned data types.\n",
    "    '''\n",
    "    # Define the data types mapping based on the processing pipeline\n",
    "    column_types = {\n",
    "        'id': int,\n",
    "        'title': str,\n",
    "        'vote_average': float,\n",
    "        'vote_count': int,\n",
    "        'status': str,\n",
    "        'revenue': float,\n",
    "        'runtime': int,\n",
    "        'adult': bool,\n",
    "        'budget': float,\n",
    "        'imdb_id': str,\n",
    "        'original_language': str,\n",
    "        'original_title': str,\n",
    "        'overview': str,\n",
    "        'popularity': float,\n",
    "        'tagline': str,\n",
    "        'genres': str,\n",
    "        'production_companies': str,\n",
    "        'production_countries': str,\n",
    "        'spoken_languages': str,\n",
    "        'release_year': int,\n",
    "        'release_date': str  # release_date remains as string when read from CSV\n",
    "    }\n",
    "    \n",
    "    # Read the CSV file back into a DataFrame with specified data types and parse dates\n",
    "    return pd.read_csv(processed_csv_path, dtype=column_types, parse_dates=['release_date'], encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV movie data into a new DataFrame\n",
    "movie_df = pd.read_csv('tmdb-movies-dataset-2023-930k-movies\\TMDB_movie_dataset_v11.csv')\n",
    "\n",
    "# Apply the main processing pipeline to your movie dataframe\n",
    "processed_movie_df = process_movie_data(movie_df, drop_na=True)\n",
    "\n",
    "# Write the processed movie data frame into a .csv file\n",
    "write_processed_movie_data(processed_movie_df, 'processed_movie_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the processed movie dataframe\n",
    "processed_movie_df = read_clean_movie_data('processed_movie_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
